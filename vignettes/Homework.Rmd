---
title: "Introduction to StatComp"
author: "Yingying Xia"
date: "`2020-12-09`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to StatComp}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

### Question 3.3
+ The Pareto$(a,b)$ distribution has cdf
$$F(x)=1-\left(\dfrac{b}{x}\right)^a,x\geq b>0,a>0.$$
Derive the probability inverse transformation $F^{-1}(U)$ and use the inverse transform method to simulate a random sample from the Pareto $(2,2)$ distribution. Graph the density histogram of the sample with the Pareto $(2,2)$ density superimposed for comparison.

- **Answer 1**
   
     The inverse transformation
     $F^{-1}(U)= b\cdot(1-U)^{-\frac{1}{a}}$,and then

```{r,echo=FALSE}
n <- 1000
u <- runif(n)
# F(x) = 1-(b/x)^a, x\geqb>0,a>0. 代入Pareto(2,2)得,x = 2*(1-u)^(-1/2)
x <- 2*(1-u)^(-1/2)
hist(x, prob = TRUE, main = expression(f(x) == 8 * x^-3))
y <- seq(0,100,.00001)
lines(y,8*y^(-3) )

```

### Question 3.9
+ The rescaled Epanechnikov kernel [85] is a symmetric density function
$$f_e(x)=\dfrac{3}{4}(1-x^2),    |x|\leq1 \tag{3.10} $$
Devroye and Gy$\ddot{o}$rfi$[71,p.236]$give the following algorithm for simulation from this distribution. Generate iid $U1,U2,U3$~$Uniform(-1,1)$.If $|U_3|\geq|U_2|$ and $|U_3|\geq|U_1|$ , deliver $U_2$; otherwise deliver $U_3$. Write a function to generate random variates from $f_e$, and construct the histogram density estimate of a large simulated random sample.

- **Answer 2**


```{r,echo=FALSE}
#建立f_e函数，输入n，返回n个符合f_e分布的样本
f_e<-function(n){
  u1<-runif(n,-1,1)
  u2<-runif(n,-1,1)
  u3<-runif(n,-1,1)
  for (i in 1:n) {
    if ( abs(u3[i]) >= abs(u1[i]) && abs(u3[i]) >= abs(u2[i]))
      u[i]=u2[i] else
      u[i]=u3[i]
  }
  return(u)
}
hist(f_e(10000),prob = TRUE)
y<-seq(-1,1,0.01)
lines(y,3/4*(1-y^2))
```

### Question 3.10
+ Prove that the algorithm given in Exercise 3.9 generates variates from the density $f_e(3.10)$.

- **Answer 3**
Given that $U_1,U_2,U_3$ iid $Uniform(-1,1)$,$(U_1,U_2,U_3)$is a random point in the cube $(-1,1)^3$. Let $X$ be the distribution generated by the given algorithm: it is obviously a symmetric distribution supported on $(-1,1)$. If we take some$\alpha \in(0,1)$, the probability that $|X|\leq\alpha$ is given by the probability that $max{|U_1|,|U_2|\leq|U_3|}$ and $|U_2|\leq\alpha$, plus the probability that $max{|U_1|,|U_2|\leq|U_3|}$ and $|U_3|\leq\alpha$,hence by:
$$\int_{0}^{\alpha}\left(\int_{0}^{u_2}(1-u_2)du_1+\int_{u_2}^{1}(1-u_1)du_1\right)du_2+\int_{0}^{\alpha}(1-u_3^2)du_3$$
that is $\dfrac{3\alpha-\alpha^3}{2}$.That gives:
$$\mathbb P(0<X\leq\alpha)=\dfrac{3\alpha-\alpha^3}{2}$$
and by differentiating with respect to αα we get that the PDF of $X$ is given by $\dfrac{3}{4}(1-x^2)$, as wanted.

2020-09-29

### Question 3.13
+  It can be shown that the mixture in Exercise 3.12 has a Pareto distribution with cdf
$$F(y)=1-(\dfrac{\beta}{\beta+y})^r, \ y\geq0$$
(This is an alternative parameterization of the Pareto cdf given in Exercise3.3.) Generate 1000 random observations from the mixture with  $\gamma=4$ and $\beta=2$.Compare the empirical and theoretical (Pareto)distributions by graphing the density histogram of the sample and superimposing the Pareto densitycurve.

- **Answer 4**

```{r,echo=FALSE}
r<-4
beta<-2
n<-1000
u<-runif(n)

#由F(y)=1-(beta\beta+y)^r, y>=0.求得以下y的表达式
y<-beta*(1/(1-u)^(1/r)-1)  

#由F(y)=1-(beta\beta+y)^r求得f(x)=r*beta^r/(beta+y)^(r+1)，代入r=4,beta=2可作图
hist(y, prob = TRUE, main = expression(f(x)==64/(2+y)^5)) 

z <- seq(0, 100, .0001)
lines(z, 64/(2+z)^5)
```

2020-10-13

### Question 5.1
+ Compute a Monte Carlo estimate of
$$\int_{0}^{\pi/3}sint dt$$
and compare your estimate with the exact value of the integral.


- **Answer 1**
  
```{r}
set.seed(12345)
m <- 1e8; 
x <- runif(m, min=0, max={pi/3})
theta.hat <- mean(sin(x)*pi/3)
print(c(theta.hat, -(cos({pi/3})-cos(0))))

```

### Question 5.7
+ Refer to Exercise 5.6. Use a Monte Carlo simulation to estimate θ by the
antithetic variate approach and by the simple Monte Carlo method. Compute
an empirical estimate of the percent reduction in variance using the antithetic
variate. Compare the result with the theoretical value from Exercise 5.6.

- **Answer 2**


```{r}
MC.Phi <- function(x, R = 10000, antithetic = TRUE) {
  u <- runif(R/2,0,x)
  if (!antithetic) 
    v <- runif(R/2) 
  else v <- 1 - u
  u <- c(u, v)
  cdf <- numeric(length(x))
  for (i in 1:length(x)) {
    g <- x[i] * exp(-(u * x[i])^2 / 2)
    cdf[i] <- mean(g) / sqrt(2 * pi) + 0.5
  }
  cdf
}
m <- 1000
MC1 <- MC2 <- numeric(m)
x <- 1.95
for (i in 1:m) {
  MC1[i] <- MC.Phi(x, R = 1000, anti = FALSE)
  MC2[i] <- MC.Phi(x, R = 1000)
}


antithetic<-function(x,m=1e4,anti=TRUE){
        theta<-numeric(m)
         if(!anti) {####simple MC method
              t<-runif(m,min=0,max=x)
              theta<-exp(t)*x
         }
        else{  ###antithetic variate approach
                u<-runif(m/2,min=0,max=x)
                v<-x-u
                t<-c(u,v)
                theta<-exp(t)*x
        }
        theta
}
a<-seq(0.1,1,length=10)
theta1<-theta2<-PR<-numeric(length(a))
for(i in 1:length(a)){
        t1<-antithetic(a[i])##antithetic estimator
        t2<-antithetic(a[i],anti=F)##simple MC estimator
        theta1[i]<-mean(t1)
        theta2[i]<-mean(t2)
        PR[i]<-100*(var(t2)-var(t1))/var(t2)###variance reduction
}
print(round(rbind(x, theta1, theta2, PR), 10))
```

### Question 5.11
+ If $\hat\theta_1$ and $\hat\theta_2$ are unbiased estimators of $\theta$, and $\hat\theta_1$ and $\hat\theta_2$ are antithetic, we
derived that $c^*=1/2$ is the optimal constant that minimizes the variance of
$\hat\theta_c=c\hat\theta_1+(1-c)\hat\theta_2$. Derive $c^*$ for the general case. That is, if $\hat\theta_1$ and $\hat\theta_2$
are any two unbiased estimators of $\theta$, find the value $c^*$ that minimizes the
variance of the estimator $\hat\theta_c=c\hat\theta_1+(1-c)\hat\theta_2$ in equation (5.11). ($c^*$ will be
a function of the variances and the covariance of the estimators.)

- **Answer 3**
解：由题意可得：
\begin{align*}
    Var(\hat\theta_c)&=c^2 \cdot Var\hat\theta_1+(1-c)^2 \cdot Var\hat\theta_2+2c(1-c)cov(\hat\theta_1,\hat\theta_2)\\
    &=Var(\hat\theta_1-\hat\theta_2) \cdot c^2-2(Var\hat\theta_2-cov(\hat\theta_1,\hat\theta_2)) \cdot c+Var\hat\theta_2\\
\end{align*}$\\$
又因为$Var(\hat\theta_1-\hat\theta_2)>0$,则$\\$
$c^*=\dfrac{Var\hat\theta_2-cov(\hat\theta_1,\hat\theta_2)}{Var(\hat\theta_1-\hat\theta_2)}$时，估计$\hat\theta_c$的方差最小。

2020-10-20

### Question 5.13
+ Find two importance functions f1 and f2 that are supported on $(1,\infty)$ and are 'close' to $$g(x)=\dfrac{x^2}{\sqrt{2\pi}}e^{-x^2/2},\qquad x>1$$.
Which of your two importance functions should produce the smaller variance
in estimating$$\int_1^{\infty}\dfrac{x^2}{\sqrt{2\pi}}e^{-x^2/2}dx$$
by importance sampling? Explain.


- **Answer 1**

&emsp;&emsp;The candidates for the importance functions are
$$f_1=\frac{2}{\sqrt{2\pi}}e^{-\frac{(x-1)^2}{2}},\quad x>1.$$
$$f_2=e^{1-x},\quad x>1.$$
&emsp;&emsp;As can be seen from the figure below, the curves of f1(x) and f2(x) are 'close' to g(x).

```{r,echo=FALSE}
g<-function(x)x^2/sqrt(2*pi)*exp(-x^2/2)
f1<-function(x)2/(sqrt(2*pi))*exp(-(x-1)^2/2)
f2<-function(x)exp(1-x)

x<-seq(1,10,0.001)
plot(x,g(x),type="l",lwd="2",col="black",main="curves of three functions")  #绘制g(x),f1(x),f2(x)曲线
lines(x,f1(x),lwd="2",col="red")   
lines(x,f2(x),lwd="2",col="blue")   
legend("topright",
       legend =c('g(x)','f1(x)',"f2(x)") ,
       lty=1,
       col=c("black","red","blue"))   


```

&emsp;&emsp;Calculate the mean and standard deviation:
```{r,echo=FALSE}
set.seed(123)
n<-10000
u<-rnorm(n)
v<-rexp(n)
a<-abs(u)+1  
b<-v+1 
theta_hat1<-mean(g(a)/f1(a))
theta_hat2<-mean(g(b)/f2(b))
est<-c(theta_hat1,theta_hat2)
sd<-c(sd(g(a)/f1(a)),sd(g(b)/f2(b)))
func<-c("f1","f2")
mydata<-data.frame(func,est,sd)
mydata
```
&emsp;&emsp;We can see that the mean of these two functions are close, but the variance of $f_1$ is smaller,so $f_1$ is a better importance function.

### Question 5.15
+ Obtain the stratified importance sampling estimate in Example 5.13 and compare it with the result of Example 5.10.

- **Answer 2**

```{r}
set.seed(1234)
n<-10000;k<-5
g<-function(x){
  exp(-x)/(1+x^2)*(x>0)*(x<1)
}
f<-function(x){
  exp(-x)/(1-exp(-1))
}

#Method1: Stratified Importance Sampling
s<-n/k
est<-numeric(k)
var<-numeric(k)
for (i in 1:k) {
  u<-runif(s,(i-1)/k,i/k)
  x<--log(1-u*(1-exp(-1))) #inverse transform
  est[i]<-mean(g(x)/f(x)) #estimate in each subinterval
  var[i]<-sd(g(x)/f(x))^2*(s-1)/s #variance in each subinterval
}
lambda_hat1.est<-mean(est)  #estimate of method1
lambda_hat1.sd<-sqrt(sum(var)/s) #sd of method1

#Method2: Importance Sampling
v<-runif(n)
y<--log(1-v*(1-exp(-1))) #inverse transform
lambda_hat2.est<-mean(g(y)/f(y))  #estimate of method2
lambda_hat2.sd<-sd(g(y)/f(y)) #sd of method2

#Compare
c(lambda_hat1.est,lambda_hat2.est)
c(lambda_hat1.sd,lambda_hat2.sd)

```
&emsp;&emsp;The results show that the standard deviation of stratified importance sampling estimation is smaller.

### Question 6.4
+ Suppose that $X_1,...,X_n$ are a random sample from a lognormal distribution with unknown parameters. Construct a $95\%$ confidence interval for the parameter $\mu$. Use a Monte Carlo method to obtain an empirical estimate of the confidence level.

- **Answer 3**

&emsp;&emsp;From the meaning of the question we have random variable $X$ that
$$logX\sim N(\mu,\sigma^2)$$
&emsp;&emsp;then we can estimate $\mu$ by its random sample $X_1,...,X_n$:
$$\hat\mu=\frac{1}{n}\sum_{i=1}^nlogX_i$$
&emsp;&emsp;and we have:
$$\frac{\sqrt{n}(\hat\mu-\mu)}{S}\sim t(n-1), \quad S^2=\frac{1}{n-1}\sum_{i=1}^n(logX_i-\hat\mu)^2$$
&emsp;&emsp;then we can get the CI:
 $$\left( { \hat\mu-\frac{S}{\sqrt n}t_{1-\frac{\alpha}{2}}(n-1),  \hat\mu+\frac{S}{\sqrt n}t_{1-\frac{\alpha}{2}}(n-1)} \right)$$

&emsp;&emsp;The code for obtaining empirical estimates of confidence levels is as follows:
```{r}
set.seed(1227)
n <- 20
mu <- 1;sigma <- 2 
alpha <- 0.05
CL <- replicate(1000,expr = {
  x <- rlnorm(n,mu,sigma)
  abs(sqrt(n/var(log(x)))*(mean(log(x))-mu)) 
})
sum(CL<qt(0.975,n-1))
mean(CL<qt(0.975,n-1))
```
It turns out to be 95% percent!


### Question 6.5
+  Suppose a $95\%$ symmetric t-interval is applied to estimate a mean, but the sample data are non-normal. Then the probability that the confidence interval covers the mean is not necessarily equal to $0.95$. Use a Monte Carlo experiment to estimate the coverage probability of the t-interval for random samples of $\chi^2(2)$ data with sample size $n = 20$. Compare your t-interval results with the simulation results in Example 6.4. (The t-interval should be more robust to departures from normality than the interval for variance.)

- **Answer 4**
```{r}
set.seed(12345)
n<-20
lambda<-2;alpha<-0.05
CL<-replicate(1000,expr = { 
  x <- rchisq(n, df = 2)
  abs(sqrt(n/var(x))*(mean(x)-lambda))
})
sum(CL<qt(0.975,n-1))
mean(CL<qt(0.975,n-1))
```
The t-interval results are quite different from the simulation results in example 6.4.

2020-10-27

### Question 6.7
+ Estimate the power of the skewness test of normality against symmetric $Beta(\alpha,\alpha)$ distributions and comment on the results. Are the results different for heavy-tailed symmetric alternatives such as $t(\nu)$?


-  **Answer 1**

```{r}
alpha <- .05
n<- 30 
m <- 2500

a<- c(seq(.1,3.6,.7),seq(6,49,1))#parameters of beta(a,a) distribution
t<-seq(1,50,1)#degrees of freedom of t distribution

sk <- function(x) {
#computes the sample skewness coeff.
xbar <- mean(x)
m3 <- mean((x - xbar)^3)
m2 <- mean((x - xbar)^2)
return( m3 / m2^1.5 )
}

N <- length(a) 
pwr1 <- pwr2 <- numeric(N) 
#critical value for the skewness test 
cv <- qnorm(1-alpha/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
sktests1 <- sktests2 <- numeric(m)
for (j in 1:N) {
  for (i in 1:m) {
    x <- rbeta(n,a[j],a[j])
    y <- rt(n,t[j])
    sktests1[i] <- as.integer(abs(sk(x)) >= cv) 
    sktests2[i] <- as.integer(abs(sk(y)) >= cv) 
    }
  pwr1[j] <- mean(sktests1) 
  pwr2[j] <- mean(sktests2) 
}

#plot power vs parameters of beta distribution
plot(a, pwr1, type = "b", xlab = "parameters of beta distribution", ylim = c(0,0.08))
se1 <- sqrt(pwr1* (1-pwr1) / m) 
#add standard errors 
lines(a, pwr1+se1, lty = 3) 
lines(a, pwr1-se1, lty = 3)

#plot power vs parameters of t distribution
plot(t, pwr2, type = "b", xlab = "parameters of t distribution", ylim = c(0,1),col="blue")
se2 <- sqrt(pwr2* (1-pwr2) / m) 
#add standard errors 
lines(t, pwr2+se2, lty = 3,col="blue") 
lines(t, pwr2-se2, lty = 3,col="blue")

#when put them together
plot(a, pwr1, type = "b", xlab = "parameters of distribution", ylab = "pwr", ylim = c(0,1))
lines(t, pwr2, type = "b", xlab = "t", ylim = c(0,1),col="blue")
abline(h = .05, lty = 3,col="blue")
legend("topright",
       legend =c("beta","t") ,
       lty=3,
       col=c("black",'blue'))
```


&emsp;&emsp;Different from the symmetric beta distribution, the potential function of the heavy-tailed distribution $t(\nu)$ is greater than 0.05, and with the increase of freedom, power decreases and tends to 0.05 gradually.$\\$

&emsp;&emsp;Therefore, the T-distribution and the normal distribution are closer than the symmetric beta distribution, which is also consistent with the intuition.

### Question 6.8
+ Refer to Example 6.16. Repeat the simulation, but also compute the $F$ test of equal variance, at significance level $\hat\alpha\dot=0.055$. Compare the power of the Count Five test and $F$ test for small, medium, and large sample sizes. (Recall
that the $F$ test is not applicable for non-normal distributions.)

-  **Answer 2**
```{r}
# generate samples under H1 to estimate power
n <- c(20,100,1000)#sample size
m <- 10000
sigma1 <- 1
sigma2 <- 1.5
power <- power2 <-  numeric(length(n))
count5test <- function(x,y){
  X <- x-mean(x)#centered by sample mean
  Y <- y-mean(y)
  outx <- sum(X>max(Y))+sum(X<min(Y))
  outy <- sum(Y>max(X))+sum(Y<min(X))
  return(as.integer(max(c(outx,outy))>5))
}
for(i in 1:length(n)){
  power[i] <- mean(replicate(m,expr = {
  x <- rnorm(n[i],0,sigma1)
  y <- rnorm(n[i],0,sigma2)
  count5test(x,y)
  }))
  pvalues <- replicate(m,expr={
    x <- rnorm(n[i],0,sigma1)
    y <- rnorm(n[i],0,sigma2)
    Ftest <- var.test(x, y, ratio = 1,
                      alternative = c("two.sided", "less", "greater"),
                      conf.level = 0.945, ...)
    Ftest$p.value})
  power2[i] <- mean(pvalues<=0.055)
}
power

power2


```

&emsp;&emsp;As can be seen from the results, power increases as the sample size increases.$\\$

&emsp;&emsp;Secondly, power is relatively large in small, medium and large samples.$\\$

&emsp;&emsp;In addition, the Power of the F test is larger than the CountFive test for small, medium, and large samples.


### Question 6.C
+  Repeat Examples 6.8 and 6.10 for Mardia’s multivariate skewness test. Mardia [187] proposed tests of multivariate normality based on multivariate generalizations of skewness and kurtosis. If $X$ and $Y$ are iid, the multivariate
population skewness $\beta_{1,d}$ is defined by Mardia as$$\beta_{1,d}=E[(X-\mu)^T\sum { }^{-1}(Y-\mu)]^3$$
Under normality, $\beta_{1,d}=0$. The multivariate skewness statistic is
$$b_{1,d}=\dfrac{1}{n^2}\sum_{i,j=1}^n((X_i-\bar X)^T\widehat\sum { }^{-1}(X_j-\bar X))^3$$
where $\widehat\sum$ is the maximum likelihood estimator of covariance. Large values of $b_{1,d}$ are significant. The asymptotic distribution of $nb_{1,d}/6$ is chisquared with $d(d+1)(d+2)/6$ degrees of freedom.

-  **Answer 3**

```{r}
library(MASS)
set.seed(123)
alpha<-0.05
d<-2
n <-c(10,20,30,50,100,500)  #sample sizes 
cv <- qchisq(1-alpha,d*(d+1)*(d+2)/6) #crit. values for each n

sk <-function(x) { 
  n<-nrow(x)
  for (i in 1:d) {
    x[,i]<-x[,i]-mean(x[,i])
  }
  s<-solve(cov(x))
  b<-mean((x%*%s%*%t(x))*(x%*%s%*%t(x))*(x%*%s%*%t(x)))
  return(b*n/6)
}
#n is a vector of sample sizes 
#we are doing length(n) different simulations
p.reject <- numeric(length(n)) #to store sim. results 
m <- 1000
#num. repl. each sim.
mu<-rep(0,d)
sigma<-diag(rep(1,d))
for (i in 1:length(n)) { 
  sktests <- numeric(m)
  for (j in 1:m) { 
    x <- mvrnorm(n[i],mu,sigma) 
    sktests[j] <- as.integer(sk(x) >= cv) 
    }
  p.reject[i] <- mean(sktests)
}
p.reject

```

```{r}
library(MASS)
set.seed(0)
alpha<-0.05
d<-2
n <-20 #sample sizes 
cv <- qchisq(1-alpha,d*(d+1)*(d+2)/6) #crit. values for each n
sk <-function(x) { 
  n<-nrow(x)
  for (i in 1:d) {
    x[,i]<-x[,i]-mean(x[,i])
  }
  s<-solve(cov(x))
  b<-mean((x%*%s%*%t(x))*(x%*%s%*%t(x))*(x%*%s%*%t(x)))
  return(b*n/6)
}

m <- 1000
epsilon <- c(seq(0, .15, .05), seq(.15, 0.9, .15)) 
N <- length(epsilon) 
pwr <- numeric(N) #critical value for the skewness test 

for (j in 1:N) {
  e <- epsilon[j] 
  sktests <- numeric(m) 
  for (i in 1:m) {
    sig <- sample(c(1,10), replace = TRUE, size = n, prob = c(1-e, e))
    x <- mvrnorm(n,rep(0,d),diag(rep(sig[1],d)))
    for (k in 2:n) {
      sigma<-diag(rep(sig[k],d))
      x <- rbind(x,mvrnorm(n,rep(0,d),sigma))
    }
    sktests[i] <- as.integer(sk(x) >= cv) 
  }
  pwr[j] <- mean(sktests) 
}
#plot power vs epsilon 
plot(epsilon, pwr, type = "b", xlab = bquote(epsilon), ylim = c(0,1))
se <- sqrt(pwr * (1-pwr) / m) #add standard errors 
lines(epsilon, pwr+se, lty = 3) 
lines(epsilon, pwr-se, lty = 3)
```


### Discussion

&emsp;&emsp;If we obtain the powers for two methods under a particular simulation setting with 10,000 experiments: say, 0.651 for one method and 0.676 for another method. Can we say the powers are different at 0.05 level?

+  1.What is the corresponding hypothesis test problem?

+  2.What test should we use? Z-test, two-sample t-test, paired-t test or McNemar test?

+  3.What information is needed to test your hypothesis?

-  **Answer 4**

&emsp;&emsp;1.$H_0:$ power1 $=$ power2 vs $H_1:$ power1 $\neq$ power2

&emsp;&emsp;2.These are all possible except for the two-sample t-test, because the two-sample t-test requires the sample to be independent.

&emsp;&emsp;3.We need the power value generated from the sample data of 10000 trials and the corresponding $\dfrac {(x_i-y_i)^2} {x_i+y_i} \sim \chi^2_1$.
We also need the chi-square quantile.

2020-11-03

### Question 7.1
+  Compute a jackknife estimate of the bias and the standard error of the correlation statistic in Example 7.2.

-  **Answer 1**

```{r warning=TRUE}
data(law, package = "bootstrap")
n <- nrow(law)
y <- law$LSAT
z <- law$GPA
theta.hat <- cor(y, z)
#compute the jackknife replicates, leave-one-out estimates
theta.jack <- numeric(n)
for (i in 1:n)
theta.jack[i] <- cor(y[-i],z[-i])
bias <- (n - 1) * (mean(theta.jack) - theta.hat)
print(bias) #jackknife estimate of bias
se <- sqrt((n-1) *
mean((theta.jack - mean(theta.jack))^2))
print(se)

```

&emsp;&emsp;So that,the jackknife estimate of the bias is -0.006473623,and the standard error is 0.1425186.


### Question 7.5
+ Refer to Exercise 7.4. Compute 95% bootstrap confidence intervals for the
mean time between failures 1/λ by the standard normal, basic, percentile,
and BCa methods. Compare the intervals and explain why they may differ.

-  **Answer 2**

```{r warning=TRUE}
library(boot)
data('aircondit')
boot.obj <- boot(aircondit,R=2000,
                 statistic = function(x,i){mean(x[i,1])})
print(boot.ci(boot.obj,type = c("basic","norm","perc")))

boot.BCa <- function(x,th0,th,stat,conf=.95){
  x <- as.matrix(x)
  n <- nrow(x)
  N <- 1:n
  alpha <- (1+c(-conf,conf))/2
  zalpha <- qnorm(alpha)
  z0 <- qnorm(sum(th<th0)/length(th))
  th.jack <- numeric(n)
  for (i in 1:n) {
    J <- N[1:(n-1)]
    th.jack[i] <- stat(x[-i, ],J)
  }
  L <- mean(th.jack)-th.jack
  a <- sum(L^3)/(6*sum(L^2)^1.5)
  adj.alpha <- pnorm(z0+(z0+zalpha)/1-a*(z0+zalpha))
  limits <- quantile(th,adj.alpha,type = 6)
  return(list("est"=th0,"BCa"=limits))
}
n <- nrow(aircondit)
B <- 2000
x <- aircondit$hours
theta.b <- numeric(B)
theta.hat <- mean(x)
for (b in 1:B) {
  i <- sample(1:n,size = n,replace = TRUE)
  x <- aircondit$hours[i]
  theta.b[b] <- mean(x)
}
stat <- function(dat,index){
  mean(dat[index])
}
boot.BCa(x,th0 = theta.hat,th=theta.b,stat=stat)

library(boot)
data('aircondit')
boot.obj <- boot(aircondit,R=2000,
                 statistic = function(x,i){mean(x[i,1])})
print(boot.ci(boot.obj,type = c("basic","norm","perc","bca")))
```
&emsp;&emsp;All four intervals cover the 1/λ=108.0833. One reason for the difference in the percentile and normal confidence intervals could be that the sampling distribution of the statistic is not close to normal. When the sampling distribution of the statistic is approximately normal, the percentile interval will agree with the normal interval.


### Question 7.8
+  Refer to Exercise 7.7. Obtain the jackknife estimates of bias and standard
error of $\hat\theta$.


-  **Answer 3**

```{r warning=TRUE}
set.seed(0)
library(boot)
library(bootstrap)
data(scor)
lambda_hat <- eigen(cov(scor))$values
theta_hat <- lambda_hat[1] / sum(lambda_hat)

n <- nrow(scor) # number of rows (data size)
# Jackknife
theta_j <- rep(0, n)
for (i in 1:n) {
x <- scor [-i,]
lambda <- eigen(cov(x))$values
theta_j[i] <- lambda[1] / sum(lambda)
# the i-th entry of theta_j is the i-th "leave-one-out" estimation of theta
}
bias_jack <- (n - 1) * (mean(theta_j) - theta_hat)
# the estimated bias of theta_hat, using jackknife
se_jack <- (n - 1) * sqrt(var(theta_j) / n)
# the estimated se of theta_hat, using jackknife
# print the answers

bias_jack
se_jack
```
So,the jackknife estimates of bias 0.001069139 and standard
error is 0.04955231.

### Question 7.11
+  In Example 7.18, leave-one-out (n-fold) cross validation was used to select the
best fitting model. Use leave-two-out cross validation to compare the models.


-  **Answer 4**

```{r message=FALSE, warning=TRUE}
library(DAAG); attach(ironslag)
n <- length(magnetic) 
e1 <- e2 <- e3 <- e4 <- matrix(0,n,n)

for (k in 1:(n-1)) {#leave the first pair of data
  mag <- magnetic[-k] 
  che <- chemical[-k]
  for (i in k:(n-1)) {#leave the second pair of data
    y <- mag[-i] 
    x <- che[-i]
    z <- c(chemical[k],chemical[i+1])
    J1 <- lm(y ~ x) 
    yhat1 <- J1$coef[1] + J1$coef[2] * z
    e1[k,i+1] <- (magnetic[k] - yhat1[1])^2 + (magnetic[i+1] - yhat1[2])^2
    
    J2 <- lm(y~x+I(x^2)) 
    yhat2 <- J2$coef[1] + J2$coef[2] * z + J2$coef[3] * z * z
    e2[k,i+1] <- (magnetic[k] - yhat2[1])^2+(magnetic[i+1] - yhat2[2])^2
    
    J3 <- lm(log(y) ~ x) 
    logyhat3 <- J3$coef[1] + J3$coef[2] * z
    yhat3 <- exp(logyhat3) 
    e3[k,i+1] <- (magnetic[k] - yhat3[1])^2+(magnetic[i+1] - yhat3[2])^2
    
    J4 <- lm(log(y) ~ log(x)) 
    logyhat4 <- J4$coef[1] + J4$coef[2] * log(z) 
    yhat4 <- exp(logyhat4) 
    e4[k,i+1] <- (magnetic[k] - yhat4[1])^2+(magnetic[i+1] - yhat4[2])^2     
  }
}
c(mean(e1),mean(e2),mean(e3),mean(e4))

```
According to the prediction error criterion, Model 2, the quadratic model,
would be the best fit for the data.

2020-11-10

### Question 8.3

+  The Count 5 test for equal variances in Section 6.4 is based on the maximum
number of extreme points. Example 6.15 shows that the Count 5 criterion
is not applicable for unequal sample sizes. Implement a permutation test for
equal variance based on the maximum number of extreme points that applies
when sample sizes are not necessarily equal.

-  **Answer 1**

The hypothesis test is: $$H_0:VarX = VarY\longleftrightarrow H_1:VarX \neq VarY$$ First, we write a function to calculate the extreme points.

We implement a permutation test for equal variance based on the maximum number of extreme points following the steps below.

Compute the observed test statistic (i.e. extreme points) $\hat{\theta}(X, Y)=\hat{\theta}(Z, \nu)$.

For each replicate, indexed b = 1, . . ., B:

Generate a random permutation $\pi_{b}=\pi(\nu)$.
Compute the statistic $\hat{\theta}^{(b)}=\hat{\theta}^{*}\left(Z, \pi_{b}\right)$.
The large values of $\hat{\theta}$ support the alternative, compute the empirical p-value by
$$\hat p=\dfrac{1+\#\begin{Bmatrix} \hat{\theta^b}\geq\hat{\theta}   \end{Bmatrix}
}{B+1}=\dfrac{\begin{Bmatrix} 1+\sum_{b=1}^BI\left(\hat\theta^b\geq\hat\theta\right) \end{Bmatrix}}{B+1}$$
Reject $H_0$ at significance level $\alpha$ if $\hat{p} \leq \alpha$.
We estimate the type1 error based on 1000 Monte Carlo experiments, and we set the significance level at 0.05

```{r}
set.seed(12345)
maxout <- function(x, y) {
X <- x - mean(x)
Y <- y - mean(y)
outx <- sum(X > max(Y)) + sum(X < min(Y))
outy <- sum(Y > max(X)) + sum(Y < min(X))
return(max(c(outx, outy)))
}

alpha <- 0.05    #significance level
n1 <- 30;n2 <-50 #two different sample size
mu1 <- mu2 <- 0;sigma1 <- sigma2 <- 1
m <- 1000   # the times of Monte Carlo experiments

p_value <- replicate(m,expr={
  x1 <- rnorm(n1,mu1,sigma1)
  x2 <- rnorm(n2,mu2,sigma2)
  ts <- numeric(199+1)
  ts[1] <- maxout(x1,x2)
  for(i in 1:199){
    ind <- sample(1:(n1+n2),size = n1,replace = FALSE)
    x.perm <- c(x1,x2)[ind]; y.perm <- c(x1,x2)[-ind]
    ts[i+1] <- maxout(x.perm,y.perm)
  }
  mean(ts >= ts[1])
})
#estimate the type1 error
print(mean(p_value < alpha))

```
As a result, we can see that the permutation method control the type1 error quite well.


### Question 2
+  Design experiments for evaluating the performance of the NN,
energy, and ball methods in various situations.
+  Unequal variances and equal expectations
+  Unequal variances and unequal expectations
+  Non-normal distributions: t distribution with 1 df(heavy-tailed distribution), bimodel distribution (mixture of two normal distributions)
+  Unbalanced samples (say, 1 case versus 10 controls)
+  Note: The parameters should be chosen such that the powers are distinguishable (say, range from 0.3 to 0.8).

-  **Answer 2**

1.For unequal variances and equal expectations
```{r}
library(RANN) # implementing a fast algorithm
# for locating nearest neighbors
# (alternative R package: "yaImpute")
library(boot)
library(energy)
library(Ball)

x <- rnorm(n1,mu1,sigma1)
y <- rnorm(n2,mu2,sigma2)
z <- c(x, y) # pooled samplec8

#R code implementing NN test
Tn <- function(z, ix, sizes,k) {
n1 <- sizes[1]; n2 <- sizes[2]; n <- n1 + n2
if(is.vector(z)) z <- data.frame(z,0);
z <- z[ix, ];
NN <- nn2(data=z, k=k+1) # what's the first column?
block1 <- NN$nn.idx[1:n1,-1]
block2 <- NN$nn.idx[(n1+1):n,-1]
i1 <- sum(block1 < n1 + .5); i2 <- sum(block2 > n1+.5)
(i1 + i2) / (k * n)
}


# Power comparison 
m <- 100; k<-3; p<-2; mu <- 0.8; set.seed(1245)
n1 <- n2 <- 10; R<-999; n <- n1+n2; N = c(n1,n2)
eqdist.nn <- function(z,sizes,k){
boot.obj <- boot(data=z,statistic=Tn,R=R,
sim = "permutation", sizes = sizes,k=k)
ts <- c(boot.obj$t0,boot.obj$t)
p.value <- mean(ts>=ts[1])
list(statistic=ts[1],p.value=p.value)
}
p.values <- matrix(NA,m,3)
for(i in 1:m){
x <- matrix(rnorm(n1*p,0,3),ncol=p);
y <- matrix(rnorm(n2*p,0,2),ncol=p);
z <- rbind(x,y)
p.values[i,1] <- eqdist.nn(z,N,k)$p.value
p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
p.values[i,3] <- bd.test(x=x,y=y,num.permutations=999,seed=i*123)$p.value
}
alpha <- 0.3;
pow1 <- colMeans(p.values<alpha)
pow1

```

2.For unequal variances and unequal expectations
```{r}
m <- 100; k<-3; p<-2; mu <- 0.5; set.seed(12345)
n1 <- n2 <- 10; R<-999; n <- n1+n2; N = c(n1,n2)
eqdist.nn <- function(z,sizes,k){
boot.obj <- boot(data=z,statistic=Tn,R=R,
sim = "permutation", sizes = sizes,k=k)
ts <- c(boot.obj$t0,boot.obj$t)
p.value <- mean(ts>=ts[1])
list(statistic=ts[1],p.value=p.value)
}
p.values <- matrix(NA,m,3)
for(i in 1:m){
x <- matrix(rnorm(n1*p,0,1),ncol=p);
y <- matrix(rnorm(n2*p,1,2),ncol=p);
z <- rbind(x,y)
p.values[i,1] <- eqdist.nn(z,N,k)$p.value
p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
p.values[i,3] <- bd.test(x=x,y=y,num.permutations=999,seed=i*12345)$p.value
}
alpha <- 0.05;
pow2 <- colMeans(p.values<alpha)
pow2

```
3.Non-normal distributions
```{r}
m <- 1e2; k<-3; p<-2; mu <- 0.3
n1 <- n2 <- 10; R<-999; n <- n1+n2; N = c(n1,n2)
p.values <- matrix(NA,m,3)

for(i in 1:m){
 x <- matrix(rt(n1*p,1),ncol = p);
  y <- cbind(rnorm(n2),rnorm(n2,mean = 1))
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z,N,k)$p.value
  p.values[i,2] <- eqdist.etest(z,sizes=N,R=999)$p.value
  p.values[i,3] <-bd.test(x=x,y=y,num.permutations=999,seed=i*12345)$p.value
}
alpha <- 0.1;
pow3 <- colMeans(p.values<alpha)
pow3

```
4.Unbalanced samples
```{r}
m <- 100; k<-3; p<-2; mu <- 0.3; set.seed(345)
n1 <- 30; n2 <- 20; R<-999; n <- n1+n2; N = c(n1,n2)
eqdist.nn <- function(z,sizes,k){
boot.obj <- boot(data=z,statistic=Tn,R=R,
sim = "permutation", sizes = sizes,k=k)
ts <- c(boot.obj$t0,boot.obj$t)
p.value <- mean(ts>=ts[1])
list(statistic=ts[1],p.value=p.value)
}
p.values <- matrix(NA,m,3)
for(i in 1:m){
x <- matrix(rnorm(n1*p,0,3.5),ncol=p);
y <- matrix(rnorm(n2*p,0,2),ncol=p);
z <- rbind(x,y)
p.values[i,1] <- eqdist.nn(z,N,k)$p.value
p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
p.values[i,3] <- bd.test(x=x,y=y,num.permutations=999,seed=i*1)$p.value
}
alpha <- 0.1;
pow4 <- colMeans(p.values<alpha)
pow4

```

```
We can see that Ball could be more powerful for non-location family distribution,and Energy test and Ball test are generally more powerful than
nearest NN test, but the former two cannot uniformly each other.

2020-11-17

### Question 1
+  Implement a random walk Metropolis sampler for generating the standard
Laplace distribution (see Exercise 3.2). For the increment, simulate from a
normal distribution. Compare the chains generated when different variances
are used for the proposal distribution. Also, compute the acceptance rates of
each chain.

-  **Answer 1**

```{r warning=FALSE, eval=FALSE}
# density of the standard Laplace distribution
r<-function(x)0.5*exp(-abs(x))
rw.Metropolis <- function(sigma, x0, N) { 
  x <- numeric(N) 
  x[1] <- x0 
  u <- runif(N) 
  k<-0 
  for (i in 2:N) {
    y <- rnorm(1, x[i-1], sigma) 
    if (u[i] <= (r(y) / r(x[i-1]))) x[i] <- y else { 
      x[i] <- x[i-1] 
      k<-k+1
    } 
  }
return(list(x=x, k=k)) 
}
N <- 5000 
sigma <- c(.05, .5, 2, 16)
x0 <- 25 
rw1 <- rw.Metropolis(sigma[1], x0, N) 
rw2 <- rw.Metropolis(sigma[2], x0, N) 
rw3 <- rw.Metropolis(sigma[3], x0, N) 
rw4 <- rw.Metropolis(sigma[4], x0, N)

#the acceptance rates of each chain
print(1-c(rw1$k, rw2$k, rw3$k, rw4$k)/2000)

plot(1:N,rw1$x,type = "l")
plot(1:N,rw2$x,type = "l")
plot(1:N,rw3$x,type = "l")
plot(1:N,rw4$x,type = "l")
```

### Question 2
+  For Exercise 9.4, use the Gelman-Rubin method to monitor convergence of the chain, and run the chain until it converges approximately to the target distribution according to $\hat R < 1.2$.

-  **Answer 2**
```{r warning=FALSE, eval=FALSE}
r<-function(x)0.5*exp(-abs(x))
Gelman.Rubin <- function(psi) { 
  # psi[i,j] is the statistic psi(X[i,1:j]) 
  # for chain in i-th row of X
  psi <- as.matrix(psi) 
  n <- ncol(psi) 
  k <- nrow(psi)
  
  psi.means <- rowMeans(psi) 
  B <- n * var(psi.means)
  psi.w <- apply(psi, 1, "var")
  W <- mean(psi.w)
  v.hat <- W*(n-1)/n + (B/n) 
  r.hat <- v.hat / W
  return(r.hat)
}

normal.chain <- function(sigma, N, X1) { 
  #generates a Metropolis chain for standard Laplace distribution
  #with Normal(X[t], sigma) proposal distribution 
  #and starting value X1 
  x <- rep(0, N) 
  x[1] <- X1 
  u <- runif(N)
  for (i in 2:N) { 
    xt <- x[i-1] 
    y <- rnorm(1, xt, sigma) 
    if (u[i] <= (r(y) / r(x[i-1]))) x[i] <- y else 
      x[i] <- x[i-1] 
  }
  return(x) 
  }
sigma <- 2 #parameter of proposal distribution 
k <- 4
n <- 15000 
b <- 1000
#number of chains to generate 
#length of chains 
#burn-in length
#choose overdispersed initial values 
x0 <- c(-10, -5, 5, 10)
#generate the chains 
X <- matrix(0, nrow=k, ncol=n) 
for (i in 1:k) X[i, ] <- normal.chain(sigma, n, x0[i])
#compute diagnostic statistics 
psi <- t(apply(X, 1, cumsum)) 
for (i in 1:nrow(psi)) psi[i,] <- psi[i,] / (1:ncol(psi)) 
print(Gelman.Rubin(psi))
#plot psi for the four chains 
for (i in 1:k) plot(psi[i, (b+1):n], type="l", xlab=i, ylab=bquote(psi))
#plot the sequence of R-hat statistics 
rhat <- rep(0, n) 
for (j in (b+1):n) rhat[j] <- Gelman.Rubin(psi[,1:j]) 
plot(rhat[(b+1):n], type="l", xlab="", ylab="R") 
abline(h=1.1, lty=2)

```

### Question 3
+  Refer to Exercise 7.7. Obtain the jackknife estimates of bias and standard
error of $\hat\theta$.

-  **Answer 3**
Find the intersection points $A(k)$ in $(0, \sqrt{k})$ of the curves
$$S_{k-1}(a)=P\left(t(k-1)>\sqrt{\frac{a^{2}(k-1)}{k-a^{2}}}\right)$$
and
$$S_{k}(a)=P\left(t(k)>\sqrt{\frac{a^{2} k}{k+1-a^{2}}}\right)$$
for k =4: 25, 100, 500, 1000, where t(k) is a Student t random variable with k degrees of freedom. (These intersection points determine the critical values for a t-test for scale-mixture errors proposed by Szekely [260].)


```{r warning=FALSE, eval=FALSE}
c_k <- function(k,a){
  sqrt(a^2*k/(k+1-a^2))
}
res <- function(k,a){
  pt(c_k(k-1,a),df = k-1) - pt(c_k(k,a),df = k)
}
root.curve <- sapply(c(4:25,100,500,1000),function(k){uniroot(res,interval = c(0.0001,sqrt(k)-0.0001),k=k)$root})#因为是开区间，所以下界比0大一点，上界比根号k小一点

result <- cbind(c(4:25,100,500,1000),root.curve)
knitr::kable(result)

```

2020-11-24

### Question 1
+  A-B-O blood type problem
    <table>
        <tr>
            <th>Genotype</th>
            <th>AA</th>
            <th>BB</th>
            <th>OO</th>
            <th>AO</th>
            <th>BO</th>
            <th>AB</th>
            <th>Sum</th>
        </tr>
        <tr>
            <th>Frequency</th>
            <th>p^2</th>
            <th>q^2</th>
            <th>r^2</th>
            <th>2pr</th>
            <th>2qr</th>
            <th>2pq</th>
            <th>1</th>
        </tr>
        <tr>
            <th>Count</th>
            <th>nAA</th>
            <th>nBB</th>
            <th>nOO</th>
            <th>nAO</th>
            <th>nBO</th>
            <th>nAB</th>
            <th>n</th>
        </tr>
    </table>

-  **Answer 1**
```{r warning=FALSE, eval=FALSE}
set.seed(1227)
n_A. <- 444
n_B. <- 132
n_AB <- 63
n_OO <- 361
p0 <- runif(1,0,1)
q0 <- runif(1,0,1-p0)
#
likelihood_e <- function(prob,p0,q0){
  r0 <- 1-p0-q0 
  p <- prob[1]; q <- prob[2] ; r <- 1-p-q
  - n_A. * (2*log(p)*(p0^2/(p0^2+2*p0*r0)) + log(2*p*r)*(2*p0*r0/(p0^2+2*p0*r0))) -
    n_B. * (2*log(q)*(q0^2/(q0^2+2*q0*r0)) + log(2*q*r)*(2*q0*r0/(q0^2+2*q0*r0))) -
    n_AB * log(2*p*q) - 2*n_OO * log(r) 
}
#
iter <- 0;E1 <- 0;E2 <- 1
while(iter < 200 && abs(E1-E2)> 1e-6){
  output <- optim(par = c(0.1,0.1),likelihood_e,p0 = p0,q0 = q0)
  E1 <- E2;E2 <- output$value
  p0 <- output$par[1]
  q0 <- output$par[2]
  iter <- iter + 1
}
estimate <- data.frame(p0,q0,iter)
colnames(estimate) <- c("p","q","iteration times")
knitr::kable(estimate)
```


### Question 2 
+  Exercises 3 (page 204, Advanced R)

Use both for loops and lapply() to fit linear models to the
mtcars using the formulas stored in this list:  
```{r warning=FALSE}
formulas <- list(
  mpg ~ disp,
  mpg ~ I(1 / disp),
  mpg ~ disp + wt,
  mpg ~ I(1 / disp) + wt
)
```
-  **Answer 2**
```{r warning=FALSE, eval=FALSE}
formulas <- list(
  mpg ~ disp,
  mpg ~ I(1 / disp),
  mpg ~ disp + wt,
  mpg ~ I(1 / disp) + wt
)

#Use for loops
models.loop <- list()
for(i in 1:length(formulas)){
  models.loop <- c(models.loop,list(lm(formulas[[i]],data = mtcars)))
}

#use lapply
models <- lapply(formulas,lm,data = mtcars)
models
```

### Question 3 

The following code simulates the performance of a t-test for non-normal data. Use sapply() and an anonymous function to extract the p-value from every trial.  

```{r warning=FALSE, eval=FALSE}
trials <- replicate(
  100,
  t.test(rpois(10, 10), rpois(7, 10)),
  simplify = FALSE
)
```

Extra challenge: get rid of the anonymous function by using it directly.

-  **Answer 3**
```{r warning=FALSE, eval=FALSE}
trials <- replicate(
  100,
  t.test(rpois(10, 10), rpois(7, 10)),
  simplify = FALSE
)
round(sapply(1:100,function(i){trials[[i]]$p.value}),3)

#Use the[[ to get rid of anonymous function.
round(sapply(trials,"[[","p.value"),3)
```

### Question 4  
Implement a combination of Map() and vapply() to create an lapply() variant that iterates in parallel over all of its inputs and stores its outputs in a vector (or a matrix). What arguments should the function take?  

-  **Answer 4**


```{r warning=FALSE, eval=FALSE}
testlist <- list(iris, mtcars, cars) 
lmapply <- function(X, FUN, FUN.VALUE, simplify = FALSE){ 
out <- Map(function(x) vapply(x, FUN, FUN.VALUE), X) 
if(simplify == TRUE){return(simplify2array(out))} 
out 
} 
lmapply(testlist, mean, numeric(1)) 
```

2020-12-01

### Question 1
1.Write an Rcpp function for Exercise 9.4 (page 277, Statistical Computing with R).  
2. Compare the corresponding generated random numbers with those by the R function you wrote before using the function “qqplot”.  
3. Campare the computation time of the two functions with the function “microbenchmark”.  
4. Comments your results.Write an Rcpp function for Exercise 9.4 .

-  **Answer 1**

```{r echo=TRUE, warning=FALSE, eval=FALSE}
library(Rcpp)
set.seed(1227)

lap_f = function(x) exp(-abs(x))

rw.Metropolis = function(sigma, x0, N){
  x = numeric(N)
  x[1] = x0
  u = runif(N)
  k = 0
  for (i in 2:N) {
    y = rnorm(1, x[i-1], sigma)
    if (u[i] <= (lap_f(y) / lap_f(x[i-1]))) x[i] = y 
    else {
      x[i] = x[i-1]
      k = k+1
    }
  }
  return(list(x = x, k = k))
}

cppFunction('List rw_Metropolis_cpp(double sigma, double x0, int N) {
  List out(2);
  NumericVector x(N);
  x[0] = x0;
  DoubleVector u = runif(N);
  int k=0;
  for(int i=1;i < N; i++) {
    double y = as<double>(rnorm(1, x[i-1], sigma));
    if (u[i] <= exp(abs(x[i-1])-abs(y))) {
      x[i] = y;
    }
    else{
      x[i] = x[i-1];
      k = k + 1;
    }
  }
  out[0] = x;
  out[1] = k;
  return (out);
}')

N = 2000
sigma = c(.05, .5, 2, 16)
x0 = 25
par(mfrow = c(2,2))

rej = numeric()
rej_c = numeric()
#chains
for (i in 1:length(sigma)) {
  par(mfrow=c(1,2))
  rw = rw.Metropolis(sigma[i],x0,N)$x
  rw_c = rw_Metropolis_cpp(sigma[i],x0,N)[[1]]
  plot(rw, type="l",
       xlab=bquote(sigma == .(round(sigma[i],3))),
       ylab="from R", ylim=range(rw))
  plot(rw_c, type="l",
       xlab=bquote(sigma == .(round(sigma[i],3))),
       ylab="from Rcpp", ylim=range(rw_c))
  rej[i] = rw.Metropolis(sigma[i],x0,N)$k
  rej_c[i] = rw_Metropolis_cpp(sigma[i],x0,N)[[2]]
}

#accept rate
acc = round((N-rej)/N,4)
acc_c = round((N-rej_c)/N,4)
res = rbind(acc, acc_c)
rownames(res) = c("Accept rates from R","Accept rates from Rcpp")
colnames(res) = paste("sigma",sigma)
knitr::kable(res)


#qqplot
for (i in 1:length(sigma)) {
  rw = rw.Metropolis(sigma[i],x0,N)$x
  rw_c = rw_Metropolis_cpp(sigma[i],x0,N)[[1]]
  qqplot(rw, rw_c, xlab = "from R", ylab = "from Rcpp", main = bquote(sigma == .(sigma[i])))
  f <- function(x) x
  curve(f, col = 'red',add = TRUE)
}

#Campare the computation time of the two functions with the function “microbenchmark”
library(microbenchmark)
for (i in 1:length(sigma)) {
  ts <- microbenchmark(rw <- rw.Metropolis(sigma[i],x0,N),
                       rw_c <- rw_Metropolis_cpp(sigma[i],x0,N))
  time <- data.frame(summary(ts)[,c(3,5,6)])
  rownames(time) <- c(paste("sigma",sigma[i],"from R"),paste("sigma",sigma[i],"from Rcpp"))
  print(knitr::kable(time))
}
```
We can conclude that the Rcpp function implement the same work as the R function do, the acceptance rate from two chains is similar, but Rcpp function consume much less time.
